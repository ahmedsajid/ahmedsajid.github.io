[{"content":"TL;DR, Jenkins EC2 plugin has the option for worker AMIs to be selected based on Tags and NOT just a hardcoded AMI ID. This comes in handy when you have an automated build pushing out AMIs with the same tags on regular basis, eliminating the need for manually updating hardcoded AMI to latest version in Jenkins EC2 cloud configuration.\nLong version\u0026hellip;\u0026hellip;\nMost companies managing their own Jenkins CI Build system on AWS Cloud must be familiar with the ec2-plugin.\nDuring my recently experience with a Jenkins setup, I found that AMI IDs were hardcoded pointing to images that were built 2 years ago. This stood out to me as a security issue, something to be dealt with right away.\nI went on a journey to figure out how to automate the process of changing the AMI on regular basis with ID of latest AMI available. Since the AMI build job already existed, all I had to do was to introduce a post-build step to update Jenkins Cloud configuration with a newly built AMI.\nSimple, right? Yeah it seemed the same to me, when I came across this PR. Some of the folks came up with a great solution which works, but has a downside. You will have to \u0026lsquo;Approve\u0026rsquo; this script within Jenkins as it considers it dangerous and might pose a security problem.\nApproving something that can have negative consequences, just didn\u0026rsquo;t sound like a great solution. I wasn\u0026rsquo;t ready to compromise on security to have a piece of automation to solve this issue.\nAfter a few days of researching, I came across this JIRA. This particular individual was having same issue when another user pointed to a feature that might help.\nFor those have worked with such a setup before probably know a simpler solution, which as you can see, I didn\u0026rsquo;t find until much later in the game.\nI feel that this is one of the GREAT features of this plugin and I was unable to find any documentation around it. I could have simply provided a list of tags to filter AMIs by and based on these tags, the plugin looks up the AMI to be the Jenkins Worker node on EC2. If there are more than 1 AMIs matching the filter, it will choose the one with latest creation date.\nIn this example you can see that I have specified multiple tags such as name, builder and os and their values as the AMI Filters.\nYou could say that I wasn\u0026rsquo;t just looking hard enough. You would be correct! I wasn\u0026rsquo;t looking hard enough in the right place.\nI hope this helps someone else going through the same struggles of figuring out this problem.\nFor more info see the actual PR which implemented this great feature.\n","permalink":"https://ahmedsajid.io/posts/jenkins-ec2-plugin-tags-filter/","summary":"TL;DR, Jenkins EC2 plugin has the option for worker AMIs to be selected based on Tags and NOT just a hardcoded AMI ID. This comes in handy when you have an automated build pushing out AMIs with the same tags on regular basis, eliminating the need for manually updating hardcoded AMI to latest version in Jenkins EC2 cloud configuration.\nLong version\u0026hellip;\u0026hellip;\nMost companies managing their own Jenkins CI Build system on AWS Cloud must be familiar with the ec2-plugin.","title":"Jenkins EC2 plugin worker AMI selection based on Resource Tags"},{"content":"Early on in my career I was responsible for compiling scientific software, installing them on HPC clusters to be used by scientists for their job runs. This is where I learned the 3 most used commands used when building and installing software. These ere configure, make and make install, as simple as that.\nFast forward years, code is longer just writing C or C++ code, these days most of the new software code is written in Golang, Python or Java just to name a few. For Golang there\u0026rsquo;s go build, Python code be compiled into a binary but most commonly shipped as-is, and Java code can be build using Maven or Gradle building JAR files.\nThis means that developers are free to choose any languages, and more often than not, the software product might even be written in a few different languages. This creates a big challenge for Development and Build engineer in selecting a Build tool that can handle multiple languages, a tool that is robust and also scalable, while ensuring fast build times.\nEnter Bazel.\nOpen source version of Google\u0026rsquo;s internal build tool Blaze. Bazel provides a way to encapsulate entire software build process, provides fast build time using caching. It is written to provide reproducible build each time.\nBazel\u0026rsquo;s principle is simple, If the inputs (source code) and parameters (running platform, build environment) haven\u0026rsquo;t changed, the built output shouldn\u0026rsquo;t change either. This means that each and every input has to be declared including outputs, based on these Bazel can ensure reproducibility (and correctness).\nBazel provides great benefits and can significantly cut down on built times of large monorepo projects. Among whole variety of features, Bazel also supports remote execution, which lets the developers perform their builds on a remote machines. This eliminates the need of large beefy laptops just so that developers are able to build code.\nThe tool also aims to provide a single way for both developer and Build system (such as Jenkins and others) use a common tool to perform builds.\nDespite all its great feature, Bazel isn\u0026rsquo;t widely adopted within industry which is largely due to do with Bazel\u0026rsquo;s steep learning curve.\n","permalink":"https://ahmedsajid.io/posts/bazel-build-system/","summary":"Early on in my career I was responsible for compiling scientific software, installing them on HPC clusters to be used by scientists for their job runs. This is where I learned the 3 most used commands used when building and installing software. These ere configure, make and make install, as simple as that.\nFast forward years, code is longer just writing C or C++ code, these days most of the new software code is written in Golang, Python or Java just to name a few.","title":"Bazel: Multi language Build Software for Monorepos"},{"content":"The most popular IaC tool at this point is HashiCorp\u0026rsquo;s Terraform. However during my usual internet browsing, I found another Infrastructure-as-Code tool Pulumi. Its been around for years at this point but I only discovered it very recently.\nPulumi achieves the same thing, Infrastructure-as-Code. However, it uses a different approach. Instead of having to write Terraform HCL files, you can use your favorite programming language such as Python or Go to write code for your infrastructure. This means you no longer have to stitch together different piece of custom written code for different set of tools to manage your platform. You can pick any of the supported Pulumi language and use it to a full end-to-end automation for your platform.\nAfter reading such great things about Pulumi, I wanted to try out Pulumi and really find out the actual benefits of using it.\nSo I wrote a simple Python Flask application Droplet Deployer which uses Pulumi in the background to make deploying and Droplets on DigitalOcean Cloud as simple as a single curl command.\ncurl -H \u0026#39;Content-Type: application/json\u0026#39; -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;\u0026lt;droplet_name\u0026gt;\u0026#34;}\u0026#39; 127.0.0.1:1337/add As you might have realized by now, the applications of Pulumi are endless.\nYou can use it to write a self-serving portal for your developers that can deploy infrastructure for their use. Pulumi can be hidden deep within your SaaS providing letting your customers deploy your software on a cloud somewhere with a click of a button. Tools can be written using Pulumi embedded within your CI/CD pipelines to manage your code deployments. and the list goes on.\nFor projects at the start out their IaC journey, I would recommend going with Pulumi from the get-go. It takes away the need to learn custom syntax which makes it trivial developers to adopt and get infrastructure deploying within minutes.\n","permalink":"https://ahmedsajid.io/posts/deploy-virtual-server-using-curl/","summary":"The most popular IaC tool at this point is HashiCorp\u0026rsquo;s Terraform. However during my usual internet browsing, I found another Infrastructure-as-Code tool Pulumi. Its been around for years at this point but I only discovered it very recently.\nPulumi achieves the same thing, Infrastructure-as-Code. However, it uses a different approach. Instead of having to write Terraform HCL files, you can use your favorite programming language such as Python or Go to write code for your infrastructure.","title":"Deploy Virtual Servers using cURL"},{"content":"While working on home server automation, I came across the awesome Open Source project healthchecks.\nI had been looking for a simple way to monitoring my Ansible home automation setup that is triggered via cron and send me alerts if my home automation takes longer than a set interval or just fails.\nhealthchecks.io, the service for healthchecks project, is an extremely simple dashboard for setting up monitoring. It also has integration with alerting systems as well as commonly used communication tools such as Teams, Slack, Signal and numerous others.\nFrom project\u0026rsquo;s website:\n Healthchecks.io works as a dead man\u0026rsquo;s switch for processes that need to run continuously or on a regular, known schedule.\n That means if the results are received within given amount of time at regular intervals, the check is considered healthy, if not the check has failed.\nResults can be submitted using curl command embedded within your script.\n# Add at the end of your script # check-uuid - custom uuid generated for your check curl https://hc-ping.com/check-uuid It also supports signals such as start to indicate start of script or a job and fail to indicate failure.\n# Beginning of your script curl https://hc-ping.com/check-uuid/start  ################## # YOUR TASKS HERE ##################  # Towards the end of the script  if [ $? -eq 0 ] then  # Post success  curl https://hc-ping.com/check-uuid else  # Post failure  curl https://hc-ping.com/check-uuid/fail fi A full range of supported API calls can be found here.\nhealthchecks.io also supports submitting logs which can then be part of the alert message.\nhealthchecks.io is trivial to setup and easy to management. Initial setup is extremely simple, it has great range of features and documentation is well written. Here\u0026rsquo;s a link to Ansible callback plugin that I\u0026rsquo;m using to integrate with healthchecks.io.\n","permalink":"https://ahmedsajid.io/posts/healthchecks.io/","summary":"While working on home server automation, I came across the awesome Open Source project healthchecks.\nI had been looking for a simple way to monitoring my Ansible home automation setup that is triggered via cron and send me alerts if my home automation takes longer than a set interval or just fails.\nhealthchecks.io, the service for healthchecks project, is an extremely simple dashboard for setting up monitoring. It also has integration with alerting systems as well as commonly used communication tools such as Teams, Slack, Signal and numerous others.","title":"Simple cron monitoring using healthchecks.io"},{"content":"I recently passed CKA and CKAD (yay me!).\nBeing that I\u0026rsquo;m very impatient and I couldn\u0026rsquo;t wait the 24 hours for my result. For people who haven\u0026rsquo;t attempted the Certified Kubernetes exams, there\u0026rsquo;s a 24 hour period between completing your exam and receiving the results.\nSo after I attempted CKAD (which came after CKA for me), I started inspecting the API calls. Users on Reddit pointed out that that exams are automatically marked and I wondered if there\u0026rsquo;s a way to figure out scores before 24 hour period.\nI started combing through API calls made on the LinuxFoundation Training Portal exam page using my browser\u0026rsquo;s developer tool Network tab. After spending some time on it, I couldn\u0026rsquo;t believe that score was right there being returned by the backend. I reckon, there\u0026rsquo;s a timer in frontend JavaScript to not display scores until the timer hits 0.\nIt was a GET call to endpoint below.\nhttps://lfx-bff.platform.linuxfoundation.org/api/faraday/reservations/active?exam=CKAD\u0026amp;email=mypersonal@email.com\u0026amp;name=Ahmed%2520Sajid\u0026amp;ldap_username=username\n","permalink":"https://ahmedsajid.io/posts/immediate-kubernetes-results/","summary":"I recently passed CKA and CKAD (yay me!).\nBeing that I\u0026rsquo;m very impatient and I couldn\u0026rsquo;t wait the 24 hours for my result. For people who haven\u0026rsquo;t attempted the Certified Kubernetes exams, there\u0026rsquo;s a 24 hour period between completing your exam and receiving the results.\nSo after I attempted CKAD (which came after CKA for me), I started inspecting the API calls. Users on Reddit pointed out that that exams are automatically marked and I wondered if there\u0026rsquo;s a way to figure out scores before 24 hour period.","title":"Immediate Kubernetes Certification Exam results"},{"content":"Page can\u0026rsquo;t be found.\nLatest content is on the homepage.\n","permalink":"https://ahmedsajid.io/404/","summary":"Page can\u0026rsquo;t be found.\nLatest content is on the homepage.","title":"Whoops! Page not found"}]